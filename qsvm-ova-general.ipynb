{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2592c1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pennylane import numpy as np\n",
    "import matplotlib as mpl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pennylane import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pennylane as qml\n",
    "import seaborn as sns\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib as mpl\n",
    "import warnings\n",
    "\n",
    "np.random.seed(1359)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9073928e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((45, 4), (105, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_data = load_iris()\n",
    "X = iris_data.data\n",
    "Y = iris_data.target\n",
    "classes = [0,1,2]\n",
    "n_classes = len(classes)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.7, random_state=42, stratify=Y)\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c51d7f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pennylane as qml\n",
    "\n",
    "def layer(x, params, wires, i0=0, inc=1):\n",
    "    \"\"\"Building block of the embedding ansatz\"\"\"\n",
    "    z1 = x*params[0] + params[1]\n",
    "    qml.RY(z1[0], 0)\n",
    "    qml.RZ(z1[1], 0)\n",
    "    qml.RY(z1[0], 0)\n",
    "    qml.RZ(z1[1], 0)\n",
    "    \n",
    "    z2 = x*params[2] + params[3]\n",
    "    qml.RY(z1[0], 1)\n",
    "    qml.RZ(z1[1], 1)\n",
    "    qml.RY(z2[0], 1)\n",
    "    qml.RZ(z2[1], 1)\n",
    "    \n",
    "    qml.CNOT((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afe2ec65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ansatz(x, params, wires):\n",
    "    \"\"\"The embedding ansatz\"\"\"\n",
    "    layer(x, params, wires)\n",
    "\n",
    "adjoint_ansatz = qml.adjoint(ansatz)\n",
    "\n",
    "def random_params():\n",
    "    \"\"\"Generate random variational parameters in the shape for the ansatz.\"\"\"\n",
    "    return np.random.uniform(0, 2 * np.pi, (4, 4), requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43a818be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = qml.device(\"default.qubit\", wires=2, shots=None)\n",
    "wires = dev.wires.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e623613",
   "metadata": {},
   "outputs": [],
   "source": [
    "@qml.qnode(dev)\n",
    "def kernel_circuit(x1, x2, params):\n",
    "    ansatz(x1, params, wires=wires)\n",
    "    adjoint_ansatz(x2, params, wires=wires)\n",
    "    return qml.probs(wires=wires)\n",
    "\n",
    "def kernel(x1, x2, params):\n",
    "    return kernel_circuit(x1, x2, params)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "306feb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [random_params() for _ in classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e17d3a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: ──RY(3.66)──RZ(0.18)──RY(3.66)──RZ(0.18)─╭●─╭●───RZ(0.20)†──RY(6.37)†──RZ(0.20)†──RY(6.37)†─┤\n",
      "1: ──RY(3.66)──RZ(0.18)──RY(6.17)──RZ(5.69)─╰X─╰X†──RZ(5.83)†──RY(7.82)†──RZ(0.20)†──RY(6.37)†─┤\n",
      "\n",
      "  ╭Probs\n",
      "  ╰Probs\n"
     ]
    }
   ],
   "source": [
    "print(qml.draw(kernel_circuit)(X_train[0], X_train[1], params[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "22dadabe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The kernel value between the first and second datapoint is 0.268\n"
     ]
    }
   ],
   "source": [
    "kernel_value = kernel(X_train[0], X_train[1], params[0])\n",
    "print(f\"The kernel value between the first and second datapoint is {kernel_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3f5e19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bf977038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(classifier, X, Y_target):\n",
    "    return 1 - np.count_nonzero(classifier.predict(X) - Y_target) / len(Y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "45c0c973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the kernel for class 0 with random parameters is 1.000\n",
      "The accuracy of a kernel for class 0 with trained parameters is 0.952\n",
      "The accuracy of the kernel for class 1 with random parameters is 0.733\n",
      "The accuracy of a kernel for class 1 with trained parameters is 0.714\n",
      "The accuracy of the kernel for class 2 with random parameters is 0.800\n",
      "The accuracy of a kernel for class 2 with trained parameters is 0.771\n"
     ]
    }
   ],
   "source": [
    "svms = []\n",
    "for i in classes:\n",
    "    y_onevsall = np.where(y_train == i, 1, -1)\n",
    "    y_onevsall_test = np.where(y_test == i, 1, -1)\n",
    "    \n",
    "    init_kernel = lambda x1, x2: kernel(x1, x2, params[i])\n",
    "    kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, init_kernel)\n",
    "    svms.append(SVC(probability=True, kernel=kernel_matrix).fit(X_train, y_onevsall))\n",
    "    \n",
    "    accuracy_init = accuracy(svms[i], X_train, y_onevsall)\n",
    "    print(f\"The accuracy of the kernel for class {i} with random parameters is {accuracy_init:.3f}\")\n",
    "    \n",
    "    accuracy_init = accuracy(svms[i], X_test, y_onevsall_test)\n",
    "    print(f\"The accuracy of a kernel for class {i} with trained parameters is {accuracy_init:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bc362be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_alignment(\n",
    "    X,\n",
    "    Y,\n",
    "    kernel,\n",
    "    assume_normalized_kernel=False,\n",
    "    rescale_class_labels=True,\n",
    "):\n",
    "    \"\"\"Kernel-target alignment between kernel and labels.\"\"\"\n",
    "\n",
    "    K = qml.kernels.square_kernel_matrix(\n",
    "        X,\n",
    "        kernel,\n",
    "        assume_normalized_kernel=assume_normalized_kernel,\n",
    "    )\n",
    "\n",
    "    if rescale_class_labels:\n",
    "        nplus = np.count_nonzero(np.array(Y) == 1)\n",
    "        nminus = len(Y) - nplus\n",
    "        _Y = np.array([y / nplus if y == 1 else y / nminus for y in Y])\n",
    "    else:\n",
    "        _Y = np.array(Y)\n",
    "\n",
    "    T = np.outer(_Y, _Y)\n",
    "    inner_product = np.sum(K * T)\n",
    "    norm = np.sqrt(np.sum(K * K) * np.sum(T * T))\n",
    "    inner_product = inner_product / norm\n",
    "\n",
    "    return inner_product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f561889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(features_train, labels_train, features_test, labels_test, params):\n",
    "    opt = qml.GradientDescentOptimizer(0.2)\n",
    "\n",
    "    for i in range(500):\n",
    "        # Choose subset of datapoints to compute the KTA on.\n",
    "        subset = np.random.choice(list(range(len(features_train))), 4)\n",
    "        # Define the cost function for optimization\n",
    "        cost = lambda _params: -target_alignment(\n",
    "            features_train[subset],\n",
    "            labels_train[subset],\n",
    "            lambda x1, x2: kernel(x1, x2, _params),\n",
    "            assume_normalized_kernel=True,\n",
    "        )\n",
    "        # Optimization step\n",
    "        params = opt.step(cost, params)\n",
    "\n",
    "        # Report the alignment on the full dataset every 50 steps.\n",
    "        if (i + 1) % 50 == 0:\n",
    "            current_alignment = target_alignment(\n",
    "                features_train,\n",
    "                labels_train,\n",
    "                lambda x1, x2: kernel(x1, x2, params),\n",
    "                assume_normalized_kernel=True,\n",
    "            )\n",
    "            print(f\"Step {i+1} - Alignment = {current_alignment:.3f}\")\n",
    "            \n",
    "    # First create a kernel with the trained parameter baked into it.\n",
    "    trained_kernel = lambda x1, x2: kernel(x1, x2, params)\n",
    "\n",
    "    # Second create a kernel matrix function using the trained kernel.\n",
    "    trained_kernel_matrix = lambda X1, X2: qml.kernels.kernel_matrix(X1, X2, trained_kernel)\n",
    "\n",
    "    # Note that SVC expects the kernel argument to be a kernel matrix function.\n",
    "    svm_trained = SVC(probability=True, kernel=trained_kernel_matrix).fit(features_train, labels_train)\n",
    "    \n",
    "    return svm_trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6871b703",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 50 - Alignment = 0.371\n",
      "Step 100 - Alignment = 0.426\n",
      "Step 150 - Alignment = 0.462\n",
      "Step 200 - Alignment = 0.481\n",
      "Step 250 - Alignment = 0.503\n",
      "Step 300 - Alignment = 0.518\n",
      "Step 350 - Alignment = 0.525\n",
      "Step 400 - Alignment = 0.525\n",
      "Step 450 - Alignment = 0.534\n",
      "Step 500 - Alignment = 0.533\n",
      "The accuracy of a kernel with trained parameters is 1.000\n",
      "The accuracy of a kernel with trained parameters is 0.990\n",
      "Step 50 - Alignment = 0.085\n",
      "Step 100 - Alignment = 0.089\n",
      "Step 150 - Alignment = 0.088\n",
      "Step 200 - Alignment = 0.097\n",
      "Step 250 - Alignment = 0.098\n",
      "Step 300 - Alignment = 0.104\n",
      "Step 350 - Alignment = 0.111\n",
      "Step 400 - Alignment = 0.117\n",
      "Step 450 - Alignment = 0.120\n",
      "Step 500 - Alignment = 0.112\n",
      "The accuracy of a kernel with trained parameters is 0.756\n",
      "The accuracy of a kernel with trained parameters is 0.771\n",
      "Step 50 - Alignment = 0.135\n",
      "Step 100 - Alignment = 0.148\n",
      "Step 150 - Alignment = 0.151\n",
      "Step 200 - Alignment = 0.155\n",
      "Step 250 - Alignment = 0.164\n",
      "Step 300 - Alignment = 0.171\n",
      "Step 350 - Alignment = 0.181\n",
      "Step 400 - Alignment = 0.185\n",
      "Step 450 - Alignment = 0.191\n",
      "Step 500 - Alignment = 0.192\n",
      "The accuracy of a kernel with trained parameters is 0.844\n",
      "The accuracy of a kernel with trained parameters is 0.810\n"
     ]
    }
   ],
   "source": [
    "svms_trained = []\n",
    "for i in classes:\n",
    "    y_onevsall = np.where(y_train == i, 1, -1)\n",
    "    y_onevsall_test = np.where(y_test == i, 1, -1)\n",
    "    svms_trained.append(run(X_train, y_onevsall, X_test, y_onevsall_test, params[i]))\n",
    "    \n",
    "    accuracy_trained = accuracy(svms_trained[i], X_train, y_onevsall)\n",
    "    print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")\n",
    "    \n",
    "    accuracy_trained = accuracy(svms_trained[i], X_test, y_onevsall_test)\n",
    "    print(f\"The accuracy of a kernel with trained parameters is {accuracy_trained:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e851179",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.repeat(np.exp(x).sum(axis = -1), 3).reshape(x.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58a4ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(features, labels):\n",
    "    probs = np.stack([svms_trained[i].predict_proba(features)[:,1] for i in classes]).T\n",
    "    predictions = softmax(probs).argmax(axis = -1)\n",
    "    return sum(predictions == labels)/len(labels)\n",
    "    print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "87dc7b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8666666666666667\n",
      "0.780952380952381\n"
     ]
    }
   ],
   "source": [
    "print(score(X_train, y_train))\n",
    "print(score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (qosf)",
   "language": "python",
   "name": "qosf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
